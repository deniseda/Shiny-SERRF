mm = lme(y~1, random = ~1|id)
x = as.numeric(VarCorr(mm)[1:2])
per[i] = x[1]/sum(x)
}
library(nlme)
per2 = c()
for(i in 1:100){
id = c(rep(1,10), 2:100)
y = rnorm(length(id))
y[1:10] = rnorm(10, sd = 0.5)
mm = lme(y~1, random = ~1|id)
x = as.numeric(VarCorr(mm)[1:2])
per2[i] = x[1]/sum(x)
}
boxplot(per, per2)
library(nlme)
per = c()
for(i in 1:100){
id = c(rep(1,10), 2:100)
y = rnorm(length(id))
y[1:10] = rnorm(10, sd = 0.5)
mm = lme(y~1, random = ~1|id)
x = as.numeric(VarCorr(mm)[1:2])
per[i] = x[1]/sum(x)
}
library(nlme)
per2 = c()
for(i in 1:100){
id = c(rep(1,10), 2:100)
y = rnorm(length(id))
y[1:10] = rnorm(10, sd = 0.5)+20
mm = lme(y~1, random = ~1|id)
x = as.numeric(VarCorr(mm)[1:2])
per2[i] = x[1]/sum(x)
}
boxplot(per, per2)
library(nlme)
per = c()
for(i in 1:100){
id = c(rep(1,10), 2:100)
y = rnorm(length(id))
y[1:10] = rnorm(10, sd = 0.5)
mm = lme(y~1, random = ~1|id)
x = as.numeric(VarCorr(mm)[1:2])
per[i] = x[1]/sum(x)
}
library(nlme)
per2 = c()
for(i in 1:100){
id = c(rep(1,10), 2:100)
y = rnorm(length(id))
y[1:10] = rnorm(10, sd = 0.5)-20
mm = lme(y~1, random = ~1|id)
x = as.numeric(VarCorr(mm)[1:2])
per2[i] = x[1]/sum(x)
}
boxplot(per, per2)
library(nlme)
per = c()
for(i in 1:100){
id = c(rep(1,10), 2:100)
y = rnorm(length(id))
y[1:10] = rnorm(10, sd = 0.5)
mm = lme(y~1, random = ~1|id)
x = as.numeric(VarCorr(mm)[1:2])
per[i] = x[1]/sum(x)
}
library(nlme)
per2 = c()
for(i in 1:100){
id = c(rep(1,10), 2:100)
y = rnorm(length(id))
y[1:10] = rnorm(10, sd = 0.5)-2
mm = lme(y~1, random = ~1|id)
x = as.numeric(VarCorr(mm)[1:2])
per2[i] = x[1]/sum(x)
}
boxplot(per, per2)
url <- a("Example Dataset", href="https://github.com/slfan2013/Shiny-SERRF/raw/master/SERRF%20example%20dataset.xlsx")
input = list(file1 = "/Users/silifan/Downloads/SERFF_input_Test.csv")
remove_outlier = function(v){
out = boxplot.stats(v)$out
return(list(value = v[!v%in%out],index = which(v%in%out)))
}
loess_wrapper_extrapolate <- function (x, y, span.vals = seq(0.25, 1, by = 0.05), folds = 5){
# Do model selection using mean absolute error, which is more robust than squared error.
mean.abs.error <- numeric(length(span.vals))
# Quantify error for each span, using CV
loess.model <- function(x, y, span){
loess(y ~ x, span = span, control=loess.control(surface="interpolate",statistics='exact'),family = "gaussian")
}
loess.predict <- function(fit, newdata) {
predict(fit, newdata = newdata)
}
span.index <- 0
for (each.span in span.vals) {
span.index <- span.index + 1
mean.abs.error[span.index] = tryCatch({
y.hat.cv <- bootstrap::crossval(x, y, theta.fit = loess.model, theta.predict = loess.predict, span = each.span, ngroup = folds)$cv.fit
non.empty.indices <- !is.na(y.hat.cv)
diff = (y[non.empty.indices] / y.hat.cv[non.empty.indices]) * mean(y[non.empty.indices])
sd(diff)/mean(diff)
},error = function(er){
NA
})
}
best.span <- span.vals[which.min(mean.abs.error)]
if(length(best.span)==0){
best.span = 0.75
}
best.model <- loess(y ~ x, span = best.span, control=loess.control(surface="interpolate",statistics='exact'),family = "gaussian")
return(list(best.model, min(mean.abs.error, na.rm = TRUE),best.span))
}
shiftData = function(ori,norm){
ori.min = apply(ori,1,min,na.rm=T)
norm.min = apply(norm,1,min,na.rm=T)
return(norm - c(norm.min - ori.min))
}
RSD = function(data){
return(apply(data,1,function(x){
x = remove_outlier(x)[[1]]
return(sd(x,na.rm=T)/mean(x,na.rm=T))
}))
}
cat("<--------- Waiting User to Select Dataset File --------->\n")
# df <- read.csv(input$file1$datapath, header = FALSE, stringsAsFactors = FALSE)
# input = list(file1 = list(datapath = "SERRF example dataset - with validate.xlsx"))
file_location = input$file1$datapath
input = list(file1 = list(datapath = "/Users/silifan/Downloads/SERFF_input_Test.csv"))
file_location = input$file1$datapath
dta = read_data(file_location)
# cat("<--------- Dataset is read --------->\n")
e = dta$e
f = dta$f
p = dta$p
if('validate'%in%p$sampleType){
with_validate = TRUE
}else{
with_validate = FALSE
}
if(e[1,1] == 167879){# example
is_example = TRUE
}else{
is_example = FALSE
}
normalized_dataset = list()
qc_RSDs = list()
methods = "SERRF"
print(is_example)
is_example
sample_rank = dta$sample_rank
qc_RSDs[["none"]] = RSD(e[,p$sampleType == 'qc'])
calculation_times = list()
# cat(paste0("Number of batches: ",length(unique(p$batch))," \n"))
start = Sys.time()
e_norm = matrix(,nrow=nrow(e),ncol=ncol(e))
QC.index = p[["sampleType"]]
batch = p[["batch"]]
time = p[["time"]]
batch = factor(batch)
num = 10
start = Sys.time();
cl = 1
serrfR = function(train = e[,p$sampleType == 'qc'],
target = e[,p$sampleType == 'sample'],
num = 10,
batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),
time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),
sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl){
all = cbind(train, target)
normalized = rep(0, ncol(all))
for(j in 1:nrow(all)){
for(b in 1:length(unique(batch.))){
current_batch = levels(batch.)[b]
all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0] = rnorm(length(all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0]))
all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])] = rnorm(length(all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])]),mean = all[j,batch.%in%current_batch][!is.na(all[j,batch.%in%current_batch])])
}
}
corrs_train = list()
corrs_target = list()
for(b in 1:length(unique(batch.))){
current_batch = levels(batch.)[b]
train_scale = t(apply(train[,batch.[sampleType.=='qc']%in%current_batch],1,scale))
if(is.null(target[,batch.[!sampleType.=='qc']%in%current_batch])){
target_scale = t(apply(target[,batch.[!sampleType.=='qc']%in%current_batch],1,scale))
}else{
target_scale = scale(target[,batch.[!sampleType.=='qc']%in%current_batch])
}
corrs_train[[current_batch]] = cor(t(train_scale), method = "spearman")
corrs_target[[current_batch]] = cor(t(target_scale), method = "spearman")
}
# pred = parSapply(cl, X = 1:nrow(all), function(j,all,batch.,ranger, sampleType., time., num,corrs_train,corrs_target){
pred = matrix(nrow = nrow(all), ncol = length(sampleType.))
withProgress(message = 'Normalization in Progress.', value = 0, {
for(j in 1:nrow(all)){
print(j)
normalized  = rep(0, ncol(all))
qc_train_value = list()
qc_predict_value = list()
sample_value = list()
sample_predict_value = list()
for(b in 1:length(levels(batch.))){
current_batch = levels(batch.)[b]
e_current_batch = all[,batch.%in%current_batch]
corr_train = corrs_train[[current_batch]]
corr_target = corrs_target[[current_batch]]
corr_train_order = order(abs(corr_train[,j]),decreasing = TRUE)
corr_target_order = order(abs(corr_target[,j]),decreasing = TRUE)
sel_var = c()
l = num
while(length(sel_var)<(num)){
sel_var = intersect(corr_train_order[1:l], corr_target_order[1:l])
sel_var = sel_var[!sel_var == j]
l = l+1
}
train.index_current_batch = sampleType.[batch.%in%current_batch]
train_data_y = scale(e_current_batch[j, train.index_current_batch=='qc'],scale=F)
train_data_x = apply(e_current_batch[sel_var, train.index_current_batch=='qc'],1,scale)
if(is.null(dim(e_current_batch[sel_var, !train.index_current_batch=='qc']))){
test_data_x = t(scale(e_current_batch[sel_var, !train.index_current_batch=='qc']))
}else{
test_data_x = apply(e_current_batch[sel_var, !train.index_current_batch=='qc'],1,scale)
}
train_NA_index  = apply(train_data_x,2,function(x){
sum(is.na(x))>0
})
train_data_x = train_data_x[,!train_NA_index]
test_data_x = test_data_x[,!train_NA_index]
if(!class(test_data_x)=="matrix"){
test_data_x = t(test_data_x)
}
good_column = apply(train_data_x,2,function(x){sum(is.na(x))==0}) & apply(test_data_x,2,function(x){sum(is.na(x))==0})
train_data_x = train_data_x[,good_column]
test_data_x = test_data_x[,good_column]
if(!class(test_data_x)=="matrix"){
test_data_x = t(test_data_x)
}
train_data = data.frame(y = train_data_y,train_data_x )
colnames(train_data) = c("y", paste0("V",1:(ncol(train_data)-1)))
model = ranger(y~., data = train_data)
test_data = data.frame(test_data_x)
colnames(test_data) = colnames(train_data)[-1]
norm = e_current_batch[j,]
norm[train.index_current_batch=='qc'] = e_current_batch[j, train.index_current_batch=='qc']/((predict(model, data = train_data)$prediction+mean(e_current_batch[j,train.index_current_batch=='qc'],na.rm=TRUE))/mean(all[j,sampleType.=='qc'],na.rm=TRUE))
# norm[!train.index_current_batch=='qc'] =(e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model, data = test_data)$prediction + mean(e_current_batch[j,!train.index_current_batch=='qc'],na.rm=TRUE))/mean(e_current_batch[j,!train.index_current_batch=='qc'],na.rm=TRUE))
norm[!train.index_current_batch=='qc'] =(e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))/(median(all[j,!sampleType.=='qc'],na.rm = TRUE)))
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
# plot(p$time[batch.%in%b][!train.index_current_batch=='qc'], (e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, train.index_current_batch=='qc'],na.rm=TRUE))/(median(e_current_batch[j,!train.index_current_batch=='qc'],na.rm = TRUE))))
norm[train.index_current_batch=='qc'] = norm[train.index_current_batch=='qc']/(median(norm[train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,sampleType.=='qc'],na.rm=TRUE))
norm[!train.index_current_batch=='qc'] = norm[!train.index_current_batch=='qc']/(median(norm[!train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,!sampleType.=='qc'],na.rm=TRUE))
norm[!is.finite(norm)] = rnorm(length(norm[!is.finite(norm)]),sd = sd(norm[is.finite(norm)],na.rm=TRUE)*0.01)
out = boxplot.stats(norm, coef = 3)$out
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']%in%out] = ((e_current_batch[j,!train.index_current_batch=='qc'])-((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))-(median(all[j,!sampleType.=='qc'],na.rm = TRUE))))[norm[!train.index_current_batch=='qc']%in%out];
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
normalized[batch.%in%current_batch] = norm
# points(current_time, norm, pch = (as.numeric(factor(train.index_current_batch))-1)*19, col = "blue", cex = 0.7)
qc_train_value[[b]] = train_data_y + mean(e_current_batch[j, train.index_current_batch=='qc'])
qc_predict_value[[b]] = predict(model,data = train_data)$predictions + mean(e_current_batch[j, train.index_current_batch=='qc'])
sample_value[[b]] = e_current_batch[j,!train.index_current_batch=='qc']
sample_predict_value[[b]] = predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'])
}
# return(normalized)
# },all,batch.,ranger, sampleType., time., num,corrs_train,corrs_target)
pred[j,] = normalized
incProgress(1/nrow(all), detail = paste("Working on compound", j,"/", nrow(all)))
}
})
normed = pred
normed_target = normed[,!sampleType.=='qc']
for(i in 1:nrow(normed_target)){
normed_target[i,is.na(normed_target[i,])] = rnorm(sum(is.na(normed_target[i,])), mean = min(normed_target[i,!is.na(normed_target[i,])], na.rm = TRUE), sd = sd(normed_target[i,!is.na(normed_target[i,])])*0.1)
}
for(i in 1:nrow(normed_target)){
normed_target[i,normed_target[i,]<0] = runif(1) * min(normed_target[i,normed_target[i,]>0], na.rm = TRUE)
}
normed_train = normed[,sampleType.=='qc']
for(i in 1:nrow(normed_train)){
normed_train[i,is.na(normed_train[i,])] = rnorm(sum(is.na(normed_train[i,])), mean = min(normed_train[i,!is.na(normed_train[i,])], na.rm = TRUE), sd = sd(normed_train[i,!is.na(normed_train[i,])])*0.1)
}
for(i in 1:nrow(normed_train)){
normed_train[i,normed_train[i,]<0] = runif(1) * min(normed_train[i,normed_train[i,]>0], na.rm = TRUE)
}
return(list(normed_train=normed_train,normed_target=normed_target))
}
serrf_normalized = e
serrf_normalized_modeled = serrfR(train = e[,p$sampleType == 'qc'], target = e[,p$sampleType == 'sample'], num = num,batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl)
serrfR = function(train = e[,p$sampleType == 'qc'],
target = e[,p$sampleType == 'sample'],
num = 10,
batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),
time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),
sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl){
all = cbind(train, target)
normalized = rep(0, ncol(all))
for(j in 1:nrow(all)){
for(b in 1:length(unique(batch.))){
current_batch = levels(batch.)[b]
all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0] = rnorm(length(all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0]))
all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])] = rnorm(length(all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])]),mean = all[j,batch.%in%current_batch][!is.na(all[j,batch.%in%current_batch])])
}
}
corrs_train = list()
corrs_target = list()
for(b in 1:length(unique(batch.))){
current_batch = levels(batch.)[b]
train_scale = t(apply(train[,batch.[sampleType.=='qc']%in%current_batch],1,scale))
if(is.null(target[,batch.[!sampleType.=='qc']%in%current_batch])){
target_scale = t(apply(target[,batch.[!sampleType.=='qc']%in%current_batch],1,scale))
}else{
target_scale = scale(target[,batch.[!sampleType.=='qc']%in%current_batch])
}
corrs_train[[current_batch]] = cor(t(train_scale), method = "spearman")
corrs_target[[current_batch]] = cor(t(target_scale), method = "spearman")
}
# pred = parSapply(cl, X = 1:nrow(all), function(j,all,batch.,ranger, sampleType., time., num,corrs_train,corrs_target){
pred = matrix(nrow = nrow(all), ncol = length(sampleType.))
# withProgress(message = 'Normalization in Progress.', value = 0, {
for(j in 1:nrow(all)){
print(j)
normalized  = rep(0, ncol(all))
qc_train_value = list()
qc_predict_value = list()
sample_value = list()
sample_predict_value = list()
for(b in 1:length(levels(batch.))){
current_batch = levels(batch.)[b]
e_current_batch = all[,batch.%in%current_batch]
corr_train = corrs_train[[current_batch]]
corr_target = corrs_target[[current_batch]]
corr_train_order = order(abs(corr_train[,j]),decreasing = TRUE)
corr_target_order = order(abs(corr_target[,j]),decreasing = TRUE)
sel_var = c()
l = num
while(length(sel_var)<(num)){
sel_var = intersect(corr_train_order[1:l], corr_target_order[1:l])
sel_var = sel_var[!sel_var == j]
l = l+1
}
train.index_current_batch = sampleType.[batch.%in%current_batch]
train_data_y = scale(e_current_batch[j, train.index_current_batch=='qc'],scale=F)
train_data_x = apply(e_current_batch[sel_var, train.index_current_batch=='qc'],1,scale)
if(is.null(dim(e_current_batch[sel_var, !train.index_current_batch=='qc']))){
test_data_x = t(scale(e_current_batch[sel_var, !train.index_current_batch=='qc']))
}else{
test_data_x = apply(e_current_batch[sel_var, !train.index_current_batch=='qc'],1,scale)
}
train_NA_index  = apply(train_data_x,2,function(x){
sum(is.na(x))>0
})
train_data_x = train_data_x[,!train_NA_index]
test_data_x = test_data_x[,!train_NA_index]
if(!class(test_data_x)=="matrix"){
test_data_x = t(test_data_x)
}
good_column = apply(train_data_x,2,function(x){sum(is.na(x))==0}) & apply(test_data_x,2,function(x){sum(is.na(x))==0})
train_data_x = train_data_x[,good_column]
test_data_x = test_data_x[,good_column]
if(!class(test_data_x)=="matrix"){
test_data_x = t(test_data_x)
}
train_data = data.frame(y = train_data_y,train_data_x )
colnames(train_data) = c("y", paste0("V",1:(ncol(train_data)-1)))
model = ranger(y~., data = train_data)
test_data = data.frame(test_data_x)
colnames(test_data) = colnames(train_data)[-1]
norm = e_current_batch[j,]
norm[train.index_current_batch=='qc'] = e_current_batch[j, train.index_current_batch=='qc']/((predict(model, data = train_data)$prediction+mean(e_current_batch[j,train.index_current_batch=='qc'],na.rm=TRUE))/mean(all[j,sampleType.=='qc'],na.rm=TRUE))
# norm[!train.index_current_batch=='qc'] =(e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model, data = test_data)$prediction + mean(e_current_batch[j,!train.index_current_batch=='qc'],na.rm=TRUE))/mean(e_current_batch[j,!train.index_current_batch=='qc'],na.rm=TRUE))
norm[!train.index_current_batch=='qc'] =(e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))/(median(all[j,!sampleType.=='qc'],na.rm = TRUE)))
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
# plot(p$time[batch.%in%b][!train.index_current_batch=='qc'], (e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, train.index_current_batch=='qc'],na.rm=TRUE))/(median(e_current_batch[j,!train.index_current_batch=='qc'],na.rm = TRUE))))
norm[train.index_current_batch=='qc'] = norm[train.index_current_batch=='qc']/(median(norm[train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,sampleType.=='qc'],na.rm=TRUE))
norm[!train.index_current_batch=='qc'] = norm[!train.index_current_batch=='qc']/(median(norm[!train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,!sampleType.=='qc'],na.rm=TRUE))
norm[!is.finite(norm)] = rnorm(length(norm[!is.finite(norm)]),sd = sd(norm[is.finite(norm)],na.rm=TRUE)*0.01)
out = boxplot.stats(norm, coef = 3)$out
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']%in%out] = ((e_current_batch[j,!train.index_current_batch=='qc'])-((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))-(median(all[j,!sampleType.=='qc'],na.rm = TRUE))))[norm[!train.index_current_batch=='qc']%in%out];
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
normalized[batch.%in%current_batch] = norm
# points(current_time, norm, pch = (as.numeric(factor(train.index_current_batch))-1)*19, col = "blue", cex = 0.7)
qc_train_value[[b]] = train_data_y + mean(e_current_batch[j, train.index_current_batch=='qc'])
qc_predict_value[[b]] = predict(model,data = train_data)$predictions + mean(e_current_batch[j, train.index_current_batch=='qc'])
sample_value[[b]] = e_current_batch[j,!train.index_current_batch=='qc']
sample_predict_value[[b]] = predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'])
}
# return(normalized)
# },all,batch.,ranger, sampleType., time., num,corrs_train,corrs_target)
pred[j,] = normalized
# incProgress(1/nrow(all), detail = paste("Working on compound", j,"/", nrow(all)))
}
# })
normed = pred
normed_target = normed[,!sampleType.=='qc']
for(i in 1:nrow(normed_target)){
normed_target[i,is.na(normed_target[i,])] = rnorm(sum(is.na(normed_target[i,])), mean = min(normed_target[i,!is.na(normed_target[i,])], na.rm = TRUE), sd = sd(normed_target[i,!is.na(normed_target[i,])])*0.1)
}
for(i in 1:nrow(normed_target)){
normed_target[i,normed_target[i,]<0] = runif(1) * min(normed_target[i,normed_target[i,]>0], na.rm = TRUE)
}
normed_train = normed[,sampleType.=='qc']
for(i in 1:nrow(normed_train)){
normed_train[i,is.na(normed_train[i,])] = rnorm(sum(is.na(normed_train[i,])), mean = min(normed_train[i,!is.na(normed_train[i,])], na.rm = TRUE), sd = sd(normed_train[i,!is.na(normed_train[i,])])*0.1)
}
for(i in 1:nrow(normed_train)){
normed_train[i,normed_train[i,]<0] = runif(1) * min(normed_train[i,normed_train[i,]>0], na.rm = TRUE)
}
return(list(normed_train=normed_train,normed_target=normed_target))
}
serrf_normalized = e
serrf_normalized_modeled = serrfR(train = e[,p$sampleType == 'qc'], target = e[,p$sampleType == 'sample'], num = num,batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl)
library(ranger)
serrf_normalized_modeled = serrfR(train = e[,p$sampleType == 'qc'], target = e[,p$sampleType == 'sample'], num = num,batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl)
cv = 3
showNotification(paste0("Performing ",cv, "-fold Cross-Validation"), duration = 15000)
serrf_normalized[,p$sampleType == 'qc'] = serrf_normalized_modeled$normed_train
serrf_normalized[,p$sampleType == 'sample'] = serrf_normalized_modeled$normed_target
qc_only_data = e[,p$sampleType=='qc']
RSDs = list()
if(any(table(p$batch[p$sampleType=='qc'])<7)){
ratio = 0.7
}else{
ratio = 0.8
}
for(k in 1:cv){
incProgress(1/cv, detail = paste("Working on the", k,"th cross-validation."))
train_index = sample(1L:sum(p$sampleType=='qc'),round(sum(p$sampleType=='qc')*ratio))
test_index = c(1L:sum(p$sampleType=='qc'))[!(c(1L:sum(p$sampleType=='qc'))%in%train_index)]
while(length(unique(batch[p$sampleType=='qc'][test_index]))<length(unique(batch))){
train_index = sample(1L:sum(p$sampleType=='qc'),round(sum(p$sampleType=='qc')*ratio))
test_index = c(1L:sum(p$sampleType=='qc'))[!(c(1L:sum(p$sampleType=='qc'))%in%train_index)]
}
serrf_normalized_on_cross_validate = serrfR(train = qc_only_data[,train_index], target = qc_only_data[,test_index], num = num,batch. = factor(c(batch[p$sampleType=='qc'][train_index],batch[p$sampleType=='qc'][test_index])),time. = c(time[p$sampleType=='qc'][train_index],time[p$sampleType=='qc'][test_index]),sampleType. = rep(c("qc","sample"),c(length(train_index),length(test_index))),cl)
RSDs[[k]] = RSD(serrf_normalized_on_cross_validate$normed_target)
}
for(k in 1:cv){
# incProgress(1/cv, detail = paste("Working on the", k,"th cross-validation."))
train_index = sample(1L:sum(p$sampleType=='qc'),round(sum(p$sampleType=='qc')*ratio))
test_index = c(1L:sum(p$sampleType=='qc'))[!(c(1L:sum(p$sampleType=='qc'))%in%train_index)]
while(length(unique(batch[p$sampleType=='qc'][test_index]))<length(unique(batch))){
train_index = sample(1L:sum(p$sampleType=='qc'),round(sum(p$sampleType=='qc')*ratio))
test_index = c(1L:sum(p$sampleType=='qc'))[!(c(1L:sum(p$sampleType=='qc'))%in%train_index)]
}
serrf_normalized_on_cross_validate = serrfR(train = qc_only_data[,train_index], target = qc_only_data[,test_index], num = num,batch. = factor(c(batch[p$sampleType=='qc'][train_index],batch[p$sampleType=='qc'][test_index])),time. = c(time[p$sampleType=='qc'][train_index],time[p$sampleType=='qc'][test_index]),sampleType. = rep(c("qc","sample"),c(length(train_index),length(test_index))),cl)
RSDs[[k]] = RSD(serrf_normalized_on_cross_validate$normed_target)
}
qc_RSD = apply(do.call("cbind",RSDs),1,mean)
serrf_normalized_validate = serrfR(train = e[,p$sampleType == 'qc'], target = e[,p$sampleType == 'validate'], num = num,batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='validate'])),time. = c(time[p$sampleType=='qc'],time[p$sampleType=='validate']),sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='validate']),cl)
e_norm = e
e_norm[,p$sampleType=='qc'] = serrf_normalized[,p$sampleType == 'qc']
e_norm[,p$sampleType=='sample'] = serrf_normalized[,p$sampleType == 'sample']
e_norm[,p$sampleType=='validate'] = serrf_normalized_validate$normed_target
rownames(e_norm) = rownames(e)
colnames(e_norm) = colnames(e)
qc_RSDs[['SERRF']] = qc_RSD
calculation_times[['SERRF']] = Sys.time() - start
cat(paste0("Average QC RSD:",signif(median(qc_RSDs[['SERRF']],na.rm = TRUE),4)*100,"%.\n"))
cat(paste0("Number of compounds less than 20% QC RSD:",sum(qc_RSDs[['SERRF']]<0.2,na.rm = TRUE),".\n"))
with_validate
if(with_validate){
val_RSDs = RSD(e[,p$sampleType == 'validate'])
val_RSDs[['SERRF']] = RSD(e_norm[,p$sampleType=='validate'])
cat(paste0("Average Validate Sample RSD:",signif(median(val_RSDs[['SERRF']],na.rm = TRUE),4)*100,"%.\n"))
cat(paste0("Number of compounds less than 20% Validate Sample RSD:",sum(val_RSDs[['SERRF']]<0.2,na.rm = TRUE),".\n"))
}
dim(e_norm)
p$sampleType=='validate'
sum(p$sampleType=='validate')
RSD(e_norm[,p$sampleType=='validate'])
val_RSDs[['SERRF']] = RSD(e_norm[,p$sampleType=='validate'])
val_RSDs
dim(e)
val_RSDs = RSD(e[,p$sampleType == 'validate'])
val_RSDs
dim(f)
length(val_RSDs)
val_RSDs = list()
val_RSDs[['none']] = RSD(e[,p$sampleType == 'validate'])
val_RSDs[['raw']] = RSD(e[,p$sampleType == 'validate'])
val_RSDs[['SERRF']] = RSD(e_norm[,p$sampleType=='validate'])
cat(paste0("Average Validate Sample RSD:",signif(median(val_RSDs[['SERRF']],na.rm = TRUE),4)*100,"%.\n"))
cat(paste0("Number of compounds less than 20% Validate Sample RSD:",sum(val_RSDs[['SERRF']]<0.2,na.rm = TRUE),".\n"))
median( val_RSDs[['raw']] )
e_norm = e_norm[,sample_rank]
cat(length(normalized_dataset))
cat(class(normalized_dataset))
normalized_dataset[["SERRF"]] = e_norm
cat(length(2))
showNotification("Preparing Result...", duration = 15000)
# stopCluster(cl)
normalized_dataset[['raw']] = e
sample_rank = dta$sample_rank
p=p[sample_rank,]
p_temp = rbind(p, dta$bad_p)
p_temp[dta$good_index] = p
p_temp[dta$bad_index] = dta$bad_p
p = p_temp
if(ncol(normalized_dataset[['raw']])==ncol(e)){
# normalized_dataset[['raw']] =  cbind(normalized_dataset[['raw']], e_other)
e_temp = cbind(normalized_dataset[['raw']], dta$bad_data_matrix)
e_temp[,dta$good_index] = normalized_dataset[['raw']]
e_temp[,dta$bad_index] = dta$bad_data_matrix
normalized_dataset[['raw']] = e_temp
}
for(i in 1:length(methods)){
# normalized_dataset[[methods[i]]] = cbind(normalized_dataset[[methods[i]]], e_other)
e_temp = cbind(normalized_dataset[[methods[i]]], dta$bad_data_matrix)
e_temp[,dta$good_index] = normalized_dataset[[methods[i]]]
e_temp[,dta$bad_index] = dta$bad_data_matrix
colnames(e_temp) = p$label
normalized_dataset[[methods[i]]] = e_temp
}
source('~/Library/Mobile Documents/com~apple~CloudDocs/PhD Biostatistics/Research/Shiny SERRF/Untitled.R', echo=TRUE)
shiny::runApp()
