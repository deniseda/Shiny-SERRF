e_norm = e_norm[,sample_rank]
cat(length(normalized_dataset))
cat(class(normalized_dataset))
normalized_dataset[["SERRF"]] = e_norm
cat(length(2))
#showNotification("Preparing Result...", duration = 15000)
# stopCluster(cl)
normalized_dataset[['raw']] = e
sample_rank = dta$sample_rank
p=p[sample_rank,]
p_temp = rbind(p, dta$bad_p)
p_temp[dta$good_index] = p
p_temp[dta$bad_index] = dta$bad_p
p = p_temp
# e = cbind(e, e_other)
if(ncol(normalized_dataset[['raw']])==ncol(e)){
# normalized_dataset[['raw']] =  cbind(normalized_dataset[['raw']], e_other)
e_temp = cbind(normalized_dataset[['raw']], dta$bad_data_matrix)
e_temp[,dta$good_index] = normalized_dataset[['raw']]
e_temp[,dta$bad_index] = dta$bad_data_matrix
normalized_dataset[['raw']] = e_temp
}
for(i in 1:length(methods)){
# normalized_dataset[[methods[i]]] = cbind(normalized_dataset[[methods[i]]], e_other)
e_temp = cbind(normalized_dataset[[methods[i]]], dta$bad_data_matrix)
e_temp[,dta$good_index] = normalized_dataset[[methods[i]]]
e_temp[,dta$bad_index] = dta$bad_data_matrix
colnames(e_temp) = p$label
normalized_dataset[[methods[i]]] = e_temp
}
# stop("Unexpected error occurred.")
}
library(ranger)
if(!is_example){
sample_rank = dta$sample_rank
qc_RSDs[["raw"]] = RSD(e[,p$sampleType == 'qc'])
calculation_times = list()
# cat(paste0("Number of batches: ",length(unique(p$batch))," \n"))
start = Sys.time()
e_norm = matrix(,nrow=nrow(e),ncol=ncol(e))
QC.index = p[["sampleType"]]
batch = p[["batch"]]
time = p[["time"]]
batch = factor(batch)
num = 10
start = Sys.time();
cl = 1
serrfR = function(train = e[,p$sampleType == 'qc'],
target = e[,p$sampleType == 'sample'],
num = 10,
batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),
time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),
sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl){
all = cbind(train, target)
normalized = rep(0, ncol(all))
for(j in 1:nrow(all)){
for(b in 1:length(unique(batch.))){
current_batch = levels(batch.)[b]
all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0] = rnorm(length(all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0]))
all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])] = rnorm(length(all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])]),mean = all[j,batch.%in%current_batch][!is.na(all[j,batch.%in%current_batch])])
}
}
corrs_train = list()
corrs_target = list()
for(b in 1:length(unique(batch.))){
current_batch = levels(batch.)[b]
train_scale = t(apply(train[,batch.[sampleType.=='qc']%in%current_batch],1,scale))
if(is.null(target[,batch.[!sampleType.=='qc']%in%current_batch])){
target_scale = t(apply(target[,batch.[!sampleType.=='qc']%in%current_batch],1,scale))
}else{
target_scale = scale(target[,batch.[!sampleType.=='qc']%in%current_batch])
}
corrs_train[[current_batch]] = cor(t(train_scale), method = "spearman")
corrs_target[[current_batch]] = cor(t(target_scale), method = "spearman")
}
# pred = parSapply(cl, X = 1:nrow(all), function(j,all,batch.,ranger, sampleType., time., num,corrs_train,corrs_target){
pred = matrix(nrow = nrow(all), ncol = length(sampleType.))
# withProgress(message = 'Normalization in Progress.', value = 0, {
for(j in 1:nrow(all)){
print(j)
normalized  = rep(0, ncol(all))
qc_train_value = list()
qc_predict_value = list()
sample_value = list()
sample_predict_value = list()
for(b in 1:length(levels(batch.))){
current_batch = levels(batch.)[b]
e_current_batch = all[,batch.%in%current_batch]
corr_train = corrs_train[[current_batch]]
corr_target = corrs_target[[current_batch]]
corr_train_order = order(abs(corr_train[,j]),decreasing = TRUE)
corr_target_order = order(abs(corr_target[,j]),decreasing = TRUE)
sel_var = c()
l = num
while(length(sel_var)<(num)){
sel_var = intersect(corr_train_order[1:l], corr_target_order[1:l])
sel_var = sel_var[!sel_var == j]
l = l+1
}
train.index_current_batch = sampleType.[batch.%in%current_batch]
train_data_y = scale(e_current_batch[j, train.index_current_batch=='qc'],scale=F)
train_data_x = apply(e_current_batch[sel_var, train.index_current_batch=='qc'],1,scale)
if(is.null(dim(e_current_batch[sel_var, !train.index_current_batch=='qc']))){
test_data_x = t(scale(e_current_batch[sel_var, !train.index_current_batch=='qc']))
}else{
test_data_x = apply(e_current_batch[sel_var, !train.index_current_batch=='qc'],1,scale)
}
train_NA_index  = apply(train_data_x,2,function(x){
sum(is.na(x))>0
})
train_data_x = train_data_x[,!train_NA_index]
test_data_x = test_data_x[,!train_NA_index]
if(!class(test_data_x)=="matrix"){
test_data_x = t(test_data_x)
}
good_column = apply(train_data_x,2,function(x){sum(is.na(x))==0}) & apply(test_data_x,2,function(x){sum(is.na(x))==0})
train_data_x = train_data_x[,good_column]
test_data_x = test_data_x[,good_column]
if(!class(test_data_x)=="matrix"){
test_data_x = t(test_data_x)
}
train_data = data.frame(y = train_data_y,train_data_x )
colnames(train_data) = c("y", paste0("V",1:(ncol(train_data)-1)))
model = ranger(y~., data = train_data)
test_data = data.frame(test_data_x)
colnames(test_data) = colnames(train_data)[-1]
norm = e_current_batch[j,]
norm[train.index_current_batch=='qc'] = e_current_batch[j, train.index_current_batch=='qc']/((predict(model, data = train_data)$prediction+mean(e_current_batch[j,train.index_current_batch=='qc'],na.rm=TRUE))/mean(all[j,sampleType.=='qc'],na.rm=TRUE))
# norm[!train.index_current_batch=='qc'] =(e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model, data = test_data)$prediction + mean(e_current_batch[j,!train.index_current_batch=='qc'],na.rm=TRUE))/mean(e_current_batch[j,!train.index_current_batch=='qc'],na.rm=TRUE))
norm[!train.index_current_batch=='qc'] =(e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))/(median(all[j,!sampleType.=='qc'],na.rm = TRUE)))
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
# plot(p$time[batch.%in%b][!train.index_current_batch=='qc'], (e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, train.index_current_batch=='qc'],na.rm=TRUE))/(median(e_current_batch[j,!train.index_current_batch=='qc'],na.rm = TRUE))))
norm[train.index_current_batch=='qc'] = norm[train.index_current_batch=='qc']/(median(norm[train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,sampleType.=='qc'],na.rm=TRUE))
norm[!train.index_current_batch=='qc'] = norm[!train.index_current_batch=='qc']/(median(norm[!train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,!sampleType.=='qc'],na.rm=TRUE))
norm[!is.finite(norm)] = rnorm(length(norm[!is.finite(norm)]),sd = sd(norm[is.finite(norm)],na.rm=TRUE)*0.01)
out = boxplot.stats(norm, coef = 3)$out
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']%in%out] = ((e_current_batch[j,!train.index_current_batch=='qc'])-((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))-(median(all[j,!sampleType.=='qc'],na.rm = TRUE))))[norm[!train.index_current_batch=='qc']%in%out];
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
normalized[batch.%in%current_batch] = norm
# points(current_time, norm, pch = (as.numeric(factor(train.index_current_batch))-1)*19, col = "blue", cex = 0.7)
qc_train_value[[b]] = train_data_y + mean(e_current_batch[j, train.index_current_batch=='qc'])
qc_predict_value[[b]] = predict(model,data = train_data)$predictions + mean(e_current_batch[j, train.index_current_batch=='qc'])
sample_value[[b]] = e_current_batch[j,!train.index_current_batch=='qc']
sample_predict_value[[b]] = predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'])
}
# return(normalized)
# },all,batch.,ranger, sampleType., time., num,corrs_train,corrs_target)
pred[j,] = normalized
incProgress(1/nrow(all), detail = paste("Working on compound", j,"/", nrow(all)))
}
# })
normed = pred
normed_target = normed[,!sampleType.=='qc']
for(i in 1:nrow(normed_target)){
normed_target[i,is.na(normed_target[i,])] = rnorm(sum(is.na(normed_target[i,])), mean = min(normed_target[i,!is.na(normed_target[i,])], na.rm = TRUE), sd = sd(normed_target[i,!is.na(normed_target[i,])])*0.1)
}
for(i in 1:nrow(normed_target)){
normed_target[i,normed_target[i,]<0] = runif(1) * min(normed_target[i,normed_target[i,]>0], na.rm = TRUE)
}
normed_train = normed[,sampleType.=='qc']
for(i in 1:nrow(normed_train)){
normed_train[i,is.na(normed_train[i,])] = rnorm(sum(is.na(normed_train[i,])), mean = min(normed_train[i,!is.na(normed_train[i,])], na.rm = TRUE), sd = sd(normed_train[i,!is.na(normed_train[i,])])*0.1)
}
for(i in 1:nrow(normed_train)){
normed_train[i,normed_train[i,]<0] = runif(1) * min(normed_train[i,normed_train[i,]>0], na.rm = TRUE)
}
return(list(normed_train=normed_train,normed_target=normed_target))
}
serrf_normalized = e
# train = e[,p$sampleType == 'qc']
# target = e[,p$sampleType == 'sample']
# batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample']))
# time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample'])
# sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample'])
serrf_normalized_modeled = serrfR(train = e[,p$sampleType == 'qc'], target = e[,p$sampleType == 'sample'], num = num,batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl)
cv = 3
#showNotification(paste0("Performing ",cv, "-fold Cross-Validation"), duration = 15000)
serrf_normalized[,p$sampleType == 'qc'] = serrf_normalized_modeled$normed_train
serrf_normalized[,p$sampleType == 'sample'] = serrf_normalized_modeled$normed_target
qc_only_data = e[,p$sampleType=='qc']
RSDs = list()
if(any(table(p$batch[p$sampleType=='qc'])<7)){
ratio = 0.7
}else{
ratio = 0.8
}
# withProgress(message = paste0(cv,'-fold Cross-Validation in Progress.'), value = 0, {
for(k in 1:cv){
incProgress(1/cv, detail = paste("Working on the", k,"th cross-validation."))
train_index = sample(1L:sum(p$sampleType=='qc'),round(sum(p$sampleType=='qc')*ratio))
test_index = c(1L:sum(p$sampleType=='qc'))[!(c(1L:sum(p$sampleType=='qc'))%in%train_index)]
while(length(unique(batch[p$sampleType=='qc'][test_index]))<length(unique(batch))){
train_index = sample(1L:sum(p$sampleType=='qc'),round(sum(p$sampleType=='qc')*ratio))
test_index = c(1L:sum(p$sampleType=='qc'))[!(c(1L:sum(p$sampleType=='qc'))%in%train_index)]
}
serrf_normalized_on_cross_validate = serrfR(train = qc_only_data[,train_index], target = qc_only_data[,test_index], num = num,batch. = factor(c(batch[p$sampleType=='qc'][train_index],batch[p$sampleType=='qc'][test_index])),time. = c(time[p$sampleType=='qc'][train_index],time[p$sampleType=='qc'][test_index]),sampleType. = rep(c("qc","sample"),c(length(train_index),length(test_index))),cl)
RSDs[[k]] = RSD(serrf_normalized_on_cross_validate$normed_target)
}
# })
qc_RSD = apply(do.call("cbind",RSDs),1,mean)
if(with_validate){
#showNotification("Working on the validate samples ...", duration = 15000)
serrf_normalized_validate = serrfR(train = e[,p$sampleType == 'qc'], target = e[,p$sampleType == 'validate'], num = num,batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='validate'])),time. = c(time[p$sampleType=='qc'],time[p$sampleType=='validate']),sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='validate']),cl)
e_norm = e
e_norm[,p$sampleType=='qc'] = serrf_normalized[,p$sampleType == 'qc']
e_norm[,p$sampleType=='sample'] = serrf_normalized[,p$sampleType == 'sample']
e_norm[,p$sampleType=='validate'] = serrf_normalized_validate$normed_target
}else{
e_norm[,p$sampleType=='qc'] = serrf_normalized[,p$sampleType == 'qc']
e_norm[,p$sampleType=='sample'] = serrf_normalized[,p$sampleType == 'sample']
}
#showNotification("Aggregating Normalized Compounds...", duration = 15000)
rownames(e_norm) = rownames(e)
colnames(e_norm) = colnames(e)
qc_RSDs[['SERRF']] = qc_RSD
calculation_times[['SERRF']] = Sys.time() - start
cat(paste0("Average QC RSD:",signif(median(qc_RSDs[['SERRF']],na.rm = TRUE),4)*100,"%.\n"))
cat(paste0("Number of compounds less than 20% QC RSD:",sum(qc_RSDs[['SERRF']]<0.2,na.rm = TRUE),".\n"))
if(with_validate){
val_RSDs = list()
val_RSDs[['raw']] = RSD(e[,p$sampleType == 'validate'])
val_RSDs[['SERRF']] = RSD(e_norm[,p$sampleType=='validate'])
cat(paste0("Average Validate Sample RSD:",signif(median(val_RSDs[['SERRF']],na.rm = TRUE),4)*100,"%.\n"))
cat(paste0("Number of compounds less than 20% Validate Sample RSD:",sum(val_RSDs[['SERRF']]<0.2,na.rm = TRUE),".\n"))
}
e_norm = e_norm[,sample_rank]
cat(length(normalized_dataset))
cat(class(normalized_dataset))
normalized_dataset[["SERRF"]] = e_norm
cat(length(2))
#showNotification("Preparing Result...", duration = 15000)
# stopCluster(cl)
normalized_dataset[['raw']] = e
sample_rank = dta$sample_rank
p=p[sample_rank,]
p_temp = rbind(p, dta$bad_p)
p_temp[dta$good_index] = p
p_temp[dta$bad_index] = dta$bad_p
p = p_temp
# e = cbind(e, e_other)
if(ncol(normalized_dataset[['raw']])==ncol(e)){
# normalized_dataset[['raw']] =  cbind(normalized_dataset[['raw']], e_other)
e_temp = cbind(normalized_dataset[['raw']], dta$bad_data_matrix)
e_temp[,dta$good_index] = normalized_dataset[['raw']]
e_temp[,dta$bad_index] = dta$bad_data_matrix
normalized_dataset[['raw']] = e_temp
}
for(i in 1:length(methods)){
# normalized_dataset[[methods[i]]] = cbind(normalized_dataset[[methods[i]]], e_other)
e_temp = cbind(normalized_dataset[[methods[i]]], dta$bad_data_matrix)
e_temp[,dta$good_index] = normalized_dataset[[methods[i]]]
e_temp[,dta$bad_index] = dta$bad_data_matrix
colnames(e_temp) = p$label
normalized_dataset[[methods[i]]] = e_temp
}
# stop("Unexpected error occurred.")
}
if(!is_example){
sample_rank = dta$sample_rank
qc_RSDs[["raw"]] = RSD(e[,p$sampleType == 'qc'])
calculation_times = list()
# cat(paste0("Number of batches: ",length(unique(p$batch))," \n"))
start = Sys.time()
e_norm = matrix(,nrow=nrow(e),ncol=ncol(e))
QC.index = p[["sampleType"]]
batch = p[["batch"]]
time = p[["time"]]
batch = factor(batch)
num = 10
start = Sys.time();
cl = 1
serrfR = function(train = e[,p$sampleType == 'qc'],
target = e[,p$sampleType == 'sample'],
num = 10,
batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),
time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),
sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl){
all = cbind(train, target)
normalized = rep(0, ncol(all))
for(j in 1:nrow(all)){
for(b in 1:length(unique(batch.))){
current_batch = levels(batch.)[b]
all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0] = rnorm(length(all[j,batch.%in%current_batch][all[j,batch.%in%current_batch] == 0]))
all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])] = rnorm(length(all[j,batch.%in%current_batch][is.na(all[j,batch.%in%current_batch])]),mean = all[j,batch.%in%current_batch][!is.na(all[j,batch.%in%current_batch])])
}
}
corrs_train = list()
corrs_target = list()
for(b in 1:length(unique(batch.))){
current_batch = levels(batch.)[b]
train_scale = t(apply(train[,batch.[sampleType.=='qc']%in%current_batch],1,scale))
if(is.null(target[,batch.[!sampleType.=='qc']%in%current_batch])){
target_scale = t(apply(target[,batch.[!sampleType.=='qc']%in%current_batch],1,scale))
}else{
target_scale = scale(target[,batch.[!sampleType.=='qc']%in%current_batch])
}
corrs_train[[current_batch]] = cor(t(train_scale), method = "spearman")
corrs_target[[current_batch]] = cor(t(target_scale), method = "spearman")
}
# pred = parSapply(cl, X = 1:nrow(all), function(j,all,batch.,ranger, sampleType., time., num,corrs_train,corrs_target){
pred = matrix(nrow = nrow(all), ncol = length(sampleType.))
# withProgress(message = 'Normalization in Progress.', value = 0, {
for(j in 1:nrow(all)){
print(j)
normalized  = rep(0, ncol(all))
qc_train_value = list()
qc_predict_value = list()
sample_value = list()
sample_predict_value = list()
for(b in 1:length(levels(batch.))){
current_batch = levels(batch.)[b]
e_current_batch = all[,batch.%in%current_batch]
corr_train = corrs_train[[current_batch]]
corr_target = corrs_target[[current_batch]]
corr_train_order = order(abs(corr_train[,j]),decreasing = TRUE)
corr_target_order = order(abs(corr_target[,j]),decreasing = TRUE)
sel_var = c()
l = num
while(length(sel_var)<(num)){
sel_var = intersect(corr_train_order[1:l], corr_target_order[1:l])
sel_var = sel_var[!sel_var == j]
l = l+1
}
train.index_current_batch = sampleType.[batch.%in%current_batch]
train_data_y = scale(e_current_batch[j, train.index_current_batch=='qc'],scale=F)
train_data_x = apply(e_current_batch[sel_var, train.index_current_batch=='qc'],1,scale)
if(is.null(dim(e_current_batch[sel_var, !train.index_current_batch=='qc']))){
test_data_x = t(scale(e_current_batch[sel_var, !train.index_current_batch=='qc']))
}else{
test_data_x = apply(e_current_batch[sel_var, !train.index_current_batch=='qc'],1,scale)
}
train_NA_index  = apply(train_data_x,2,function(x){
sum(is.na(x))>0
})
train_data_x = train_data_x[,!train_NA_index]
test_data_x = test_data_x[,!train_NA_index]
if(!class(test_data_x)=="matrix"){
test_data_x = t(test_data_x)
}
good_column = apply(train_data_x,2,function(x){sum(is.na(x))==0}) & apply(test_data_x,2,function(x){sum(is.na(x))==0})
train_data_x = train_data_x[,good_column]
test_data_x = test_data_x[,good_column]
if(!class(test_data_x)=="matrix"){
test_data_x = t(test_data_x)
}
train_data = data.frame(y = train_data_y,train_data_x )
colnames(train_data) = c("y", paste0("V",1:(ncol(train_data)-1)))
model = ranger(y~., data = train_data)
test_data = data.frame(test_data_x)
colnames(test_data) = colnames(train_data)[-1]
norm = e_current_batch[j,]
norm[train.index_current_batch=='qc'] = e_current_batch[j, train.index_current_batch=='qc']/((predict(model, data = train_data)$prediction+mean(e_current_batch[j,train.index_current_batch=='qc'],na.rm=TRUE))/mean(all[j,sampleType.=='qc'],na.rm=TRUE))
# norm[!train.index_current_batch=='qc'] =(e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model, data = test_data)$prediction + mean(e_current_batch[j,!train.index_current_batch=='qc'],na.rm=TRUE))/mean(e_current_batch[j,!train.index_current_batch=='qc'],na.rm=TRUE))
norm[!train.index_current_batch=='qc'] =(e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))/(median(all[j,!sampleType.=='qc'],na.rm = TRUE)))
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
# plot(p$time[batch.%in%b][!train.index_current_batch=='qc'], (e_current_batch[j,!train.index_current_batch=='qc'])/((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, train.index_current_batch=='qc'],na.rm=TRUE))/(median(e_current_batch[j,!train.index_current_batch=='qc'],na.rm = TRUE))))
norm[train.index_current_batch=='qc'] = norm[train.index_current_batch=='qc']/(median(norm[train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,sampleType.=='qc'],na.rm=TRUE))
norm[!train.index_current_batch=='qc'] = norm[!train.index_current_batch=='qc']/(median(norm[!train.index_current_batch=='qc'],na.rm=TRUE)/median(all[j,!sampleType.=='qc'],na.rm=TRUE))
norm[!is.finite(norm)] = rnorm(length(norm[!is.finite(norm)]),sd = sd(norm[is.finite(norm)],na.rm=TRUE)*0.01)
out = boxplot.stats(norm, coef = 3)$out
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']%in%out] = ((e_current_batch[j,!train.index_current_batch=='qc'])-((predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'],na.rm=TRUE))-(median(all[j,!sampleType.=='qc'],na.rm = TRUE))))[norm[!train.index_current_batch=='qc']%in%out];
norm[!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]=e_current_batch[j,!train.index_current_batch=='qc'][norm[!train.index_current_batch=='qc']<0]
normalized[batch.%in%current_batch] = norm
# points(current_time, norm, pch = (as.numeric(factor(train.index_current_batch))-1)*19, col = "blue", cex = 0.7)
qc_train_value[[b]] = train_data_y + mean(e_current_batch[j, train.index_current_batch=='qc'])
qc_predict_value[[b]] = predict(model,data = train_data)$predictions + mean(e_current_batch[j, train.index_current_batch=='qc'])
sample_value[[b]] = e_current_batch[j,!train.index_current_batch=='qc']
sample_predict_value[[b]] = predict(model,data = test_data)$predictions  + mean(e_current_batch[j, !train.index_current_batch=='qc'])
}
# return(normalized)
# },all,batch.,ranger, sampleType., time., num,corrs_train,corrs_target)
pred[j,] = normalized
# incProgress(1/nrow(all), detail = paste("Working on compound", j,"/", nrow(all)))
}
# })
normed = pred
normed_target = normed[,!sampleType.=='qc']
for(i in 1:nrow(normed_target)){
normed_target[i,is.na(normed_target[i,])] = rnorm(sum(is.na(normed_target[i,])), mean = min(normed_target[i,!is.na(normed_target[i,])], na.rm = TRUE), sd = sd(normed_target[i,!is.na(normed_target[i,])])*0.1)
}
for(i in 1:nrow(normed_target)){
normed_target[i,normed_target[i,]<0] = runif(1) * min(normed_target[i,normed_target[i,]>0], na.rm = TRUE)
}
normed_train = normed[,sampleType.=='qc']
for(i in 1:nrow(normed_train)){
normed_train[i,is.na(normed_train[i,])] = rnorm(sum(is.na(normed_train[i,])), mean = min(normed_train[i,!is.na(normed_train[i,])], na.rm = TRUE), sd = sd(normed_train[i,!is.na(normed_train[i,])])*0.1)
}
for(i in 1:nrow(normed_train)){
normed_train[i,normed_train[i,]<0] = runif(1) * min(normed_train[i,normed_train[i,]>0], na.rm = TRUE)
}
return(list(normed_train=normed_train,normed_target=normed_target))
}
serrf_normalized = e
# train = e[,p$sampleType == 'qc']
# target = e[,p$sampleType == 'sample']
# batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample']))
# time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample'])
# sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample'])
serrf_normalized_modeled = serrfR(train = e[,p$sampleType == 'qc'], target = e[,p$sampleType == 'sample'], num = num,batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='sample'])),time. = c(time[p$sampleType=='qc'],time[p$sampleType=='sample']),sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='sample']),cl)
cv = 3
#showNotification(paste0("Performing ",cv, "-fold Cross-Validation"), duration = 15000)
serrf_normalized[,p$sampleType == 'qc'] = serrf_normalized_modeled$normed_train
serrf_normalized[,p$sampleType == 'sample'] = serrf_normalized_modeled$normed_target
qc_only_data = e[,p$sampleType=='qc']
RSDs = list()
if(any(table(p$batch[p$sampleType=='qc'])<7)){
ratio = 0.7
}else{
ratio = 0.8
}
# withProgress(message = paste0(cv,'-fold Cross-Validation in Progress.'), value = 0, {
for(k in 1:cv){
# incProgress(1/cv, detail = paste("Working on the", k,"th cross-validation."))
train_index = sample(1L:sum(p$sampleType=='qc'),round(sum(p$sampleType=='qc')*ratio))
test_index = c(1L:sum(p$sampleType=='qc'))[!(c(1L:sum(p$sampleType=='qc'))%in%train_index)]
while(length(unique(batch[p$sampleType=='qc'][test_index]))<length(unique(batch))){
train_index = sample(1L:sum(p$sampleType=='qc'),round(sum(p$sampleType=='qc')*ratio))
test_index = c(1L:sum(p$sampleType=='qc'))[!(c(1L:sum(p$sampleType=='qc'))%in%train_index)]
}
serrf_normalized_on_cross_validate = serrfR(train = qc_only_data[,train_index], target = qc_only_data[,test_index], num = num,batch. = factor(c(batch[p$sampleType=='qc'][train_index],batch[p$sampleType=='qc'][test_index])),time. = c(time[p$sampleType=='qc'][train_index],time[p$sampleType=='qc'][test_index]),sampleType. = rep(c("qc","sample"),c(length(train_index),length(test_index))),cl)
RSDs[[k]] = RSD(serrf_normalized_on_cross_validate$normed_target)
}
# })
qc_RSD = apply(do.call("cbind",RSDs),1,mean)
if(with_validate){
#showNotification("Working on the validate samples ...", duration = 15000)
serrf_normalized_validate = serrfR(train = e[,p$sampleType == 'qc'], target = e[,p$sampleType == 'validate'], num = num,batch. = factor(c(batch[p$sampleType=='qc'],batch[p$sampleType=='validate'])),time. = c(time[p$sampleType=='qc'],time[p$sampleType=='validate']),sampleType. = c(p$sampleType[p$sampleType=='qc'],p$sampleType[p$sampleType=='validate']),cl)
e_norm = e
e_norm[,p$sampleType=='qc'] = serrf_normalized[,p$sampleType == 'qc']
e_norm[,p$sampleType=='sample'] = serrf_normalized[,p$sampleType == 'sample']
e_norm[,p$sampleType=='validate'] = serrf_normalized_validate$normed_target
}else{
e_norm[,p$sampleType=='qc'] = serrf_normalized[,p$sampleType == 'qc']
e_norm[,p$sampleType=='sample'] = serrf_normalized[,p$sampleType == 'sample']
}
#showNotification("Aggregating Normalized Compounds...", duration = 15000)
rownames(e_norm) = rownames(e)
colnames(e_norm) = colnames(e)
qc_RSDs[['SERRF']] = qc_RSD
calculation_times[['SERRF']] = Sys.time() - start
cat(paste0("Average QC RSD:",signif(median(qc_RSDs[['SERRF']],na.rm = TRUE),4)*100,"%.\n"))
cat(paste0("Number of compounds less than 20% QC RSD:",sum(qc_RSDs[['SERRF']]<0.2,na.rm = TRUE),".\n"))
if(with_validate){
val_RSDs = list()
val_RSDs[['raw']] = RSD(e[,p$sampleType == 'validate'])
val_RSDs[['SERRF']] = RSD(e_norm[,p$sampleType=='validate'])
cat(paste0("Average Validate Sample RSD:",signif(median(val_RSDs[['SERRF']],na.rm = TRUE),4)*100,"%.\n"))
cat(paste0("Number of compounds less than 20% Validate Sample RSD:",sum(val_RSDs[['SERRF']]<0.2,na.rm = TRUE),".\n"))
}
e_norm = e_norm[,sample_rank]
cat(length(normalized_dataset))
cat(class(normalized_dataset))
normalized_dataset[["SERRF"]] = e_norm
cat(length(2))
#showNotification("Preparing Result...", duration = 15000)
# stopCluster(cl)
normalized_dataset[['raw']] = e
sample_rank = dta$sample_rank
p=p[sample_rank,]
p_temp = rbind(p, dta$bad_p)
p_temp[dta$good_index] = p
p_temp[dta$bad_index] = dta$bad_p
p = p_temp
# e = cbind(e, e_other)
if(ncol(normalized_dataset[['raw']])==ncol(e)){
# normalized_dataset[['raw']] =  cbind(normalized_dataset[['raw']], e_other)
e_temp = cbind(normalized_dataset[['raw']], dta$bad_data_matrix)
e_temp[,dta$good_index] = normalized_dataset[['raw']]
e_temp[,dta$bad_index] = dta$bad_data_matrix
normalized_dataset[['raw']] = e_temp
}
for(i in 1:length(methods)){
# normalized_dataset[[methods[i]]] = cbind(normalized_dataset[[methods[i]]], e_other)
e_temp = cbind(normalized_dataset[[methods[i]]], dta$bad_data_matrix)
e_temp[,dta$good_index] = normalized_dataset[[methods[i]]]
e_temp[,dta$bad_index] = dta$bad_data_matrix
colnames(e_temp) = p$label
normalized_dataset[[methods[i]]] = e_temp
}
# stop("Unexpected error occurred.")
}
qc_RSD_performance = sapply(qc_RSDs,median, na.rm = TRUE)
qc_RSD_performance = sort(qc_RSD_performance,decreasing = TRUE)
qc_RSD_performance_color = rep("grey",length(qc_RSD_performance))
qc_RSD_performance_color[length(qc_RSD_performance_color)-1] = "red"
qc_RSD_performance_color[length(qc_RSD_performance_color)] = "#ffbf00"
qc_RSD_performance_color[names(qc_RSD_performance)=='raw'] = 'black'
val_RSD_performance = sapply(val_RSDs,median, na.rm = TRUE)
val_RSD_performance = sort(val_RSD_performance,decreasing = TRUE)
val_RSD_performance_color = rep("grey",length(val_RSD_performance))
val_RSD_performance_color[length(val_RSD_performance_color)-1] = "red"
val_RSD_performance_color[length(val_RSD_performance_color)] = "#ffbf00"
val_RSD_performance_color[names(val_RSD_performance)=='raw'] = 'black'
layout(matrix(c(1,1,2,2), 2, 2, byrow = TRUE))
qc_RSDs
RSDs = data.table(label = f$label, do.call('cbind',qc_RSDs))
val_RSDs
with_validate
colnames(val_RSDs)
names(val_RSDs)
names(val_RSDs) = paste0(names(val_RSDs),"-validate")
RSDs = cbind(RSDs, do.call("cbind",val_RSDs))
fwrite(RSDs,"RSDs.csv")
getwd()
exp(-16/3802*36)
exp(-8/623*36)
pacman::p_load(KMsurv)
data(btrial)
btrial
write.csv(btrial, "btrial.csv")
getwd()
?phyper
